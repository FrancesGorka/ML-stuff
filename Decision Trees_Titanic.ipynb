{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c05da0-baea-40a1-b9af-a975ee29baa6",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 24px;\">The Titanic Problem.</span>\n",
    "\n",
    "Key skills covered: Binary Classification, decision trees, hyperparameters for decision trees, gini impurity, k-fold-cross-validation, evaluation methods for classification problems, k nearest neighbours, preprocessing with sklearn, feature engineering best practice\n",
    "\n",
    "We're dealing with a binary classification problem, the dataset is relatively small, (<1000) and the features have a mixture of categorial and numerical data so a decision tree will most likely work relatively well. This is what we'll start with.\n",
    "\n",
    "CORRECTION - high dimensionality is not good for decision trees. Should not use one hot vectors to encode categorical variables and use label encoding instead. This is what I originally did and then switched to label encoding.\n",
    "\n",
    "First the data needs cleaning and preparing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1663d2e6-cf53-4631-a50b-e8d5ca7c1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "path_train = \"/home/frances/Documents/Getting a JOB/ML preparation/Titanic_Classification/train.csv\"\n",
    "path_test = \"/home/frances/Documents/Getting a JOB/ML preparation/Titanic_Classification/test.csv\"\n",
    "\n",
    "train_data = pd.read_csv(path_train)\n",
    "test_data = pd.read_csv(path_test)\n",
    "\n",
    "# Create a new instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to 'Sex' and 'Embarked' columns in training data\n",
    "train_data['Sex'] = label_encoder.fit_transform(train_data['Sex'])\n",
    "train_data['Embarked'] = label_encoder.fit_transform(train_data['Embarked'])\n",
    "test_data['Sex'] = label_encoder.fit_transform(test_data['Sex'])\n",
    "test_data['Embarked'] = label_encoder.fit_transform(test_data['Embarked'])\n",
    "\n",
    "X_train = train_data.drop(['Name', 'Parch', 'Ticket','Cabin'],axis=1) # remove unnecessary columns\n",
    "X_test = test_data.drop(['Name', 'Parch', 'Ticket','Cabin'],axis=1) # remove unnecessary columns\n",
    "\n",
    "# There are 177 na values in the train set, and 87 na values in the test data, which is very high so I don't want to drop them.\n",
    "\n",
    "cols_with_missing_data = ['Age','Fare']\n",
    "\n",
    "# There are 891 samples, sqrt(891) = 30 so I'll use 30 nearest neighbours.\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=30)\n",
    "\n",
    "# Perform imputation on training data\n",
    "imputed_train_data = X_train.copy()\n",
    "imputed_train_data[cols_with_missing_data] = knn_imputer.fit_transform(X_train[cols_with_missing_data])\n",
    "\n",
    "# Perform imputation on test data\n",
    "imputed_test_data = X_test.copy()\n",
    "imputed_test_data[cols_with_missing_data] = knn_imputer.transform(X_test[cols_with_missing_data])\n",
    "\n",
    "X_train = imputed_train_data\n",
    "X_test = imputed_test_data\n",
    "\n",
    "Y_train = X_train['Survived']\n",
    "X_train = X_train.drop(['Survived'],axis=1) # remove unnecessary columns\n",
    "\n",
    "X_train['SibSp'] = np.log(X_train['SibSp'] + 1)  # Adding 1 to handle zero values\n",
    "X_train['Fare'] = np.log(X_train['Fare'] + 1)\n",
    "X_test['SibSp'] = np.log(X_test['SibSp'] + 1) \n",
    "X_test['Fare'] = np.log(X_test['Fare'] + 1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same scaler\n",
    "X_test= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8be922-c895-436c-88bd-4057e081e3e2",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px;\">Decision Trees</span>\n",
    "\n",
    "Decision trees are easy to interpret and can handle both numerical and categorical data. They are a simple model, they don’t capture complex behaviour and they can easily overfit. Decision trees work by iteratively (at each branch) picking the ‘best feature’ with which to separate the data. This is based on ‘purity’ for classification tasks and ‘variance’ for regression tasks. \n",
    "\n",
    "<b> Explanation of Gini purity </b>\n",
    "\n",
    "Gini = 1 - ∑(p_i)^2\n",
    "\n",
    "So for each class, you see the proportion of data points belonging to it, and you square that value and sum it and take it away from 1. \n",
    "\n",
    "If values for an input variable e.g. Weather = Sunny, Weather = Cloudy, are fairly spread out across the classes (i.e. if they fall into Yes or No more evenly) then they aren't a very good predictor of the outcome. The proportions of data points in each class are likely to be very close, resulting in small values of the summand term. Which means the whole metric will be closer to 1, indicating impurity. The best variable is the purest variable.\n",
    "\n",
    "<b> Explanation of variance </b>\n",
    "\n",
    "It’s similar for regression problems, except you minimise variance. \n",
    "\n",
    "<b> Hyperparameters </b>\n",
    "\n",
    "Criterions: methodology to split the data/create branches e.g. Gini impurity\n",
    "\n",
    "Things which prevent overfitting/control tree architecture:\n",
    "- Max Depth: It limits the number of levels the tree can grow. Setting this hyperparameter can help prevent overfitting.\n",
    "- Min Samples Split: The minimum number of samples required to split an internal node. If a node has fewer samples than this value, it will not be split further.\n",
    "- Min Samples Leaf: The minimum number of samples required to be at a leaf node. This hyperparameter helps control the size of the tree.\n",
    "\n",
    "Splitter: This hyperparameter specifies the strategy used to choose the split at each node. Common values are \"best\" (choose the best split) and \"random\" (choose the best random split).\n",
    "\n",
    "Class Weight: For imbalanced datasets, you can use this hyperparameter to assign different weights to different classes. It can help the decision tree model to give more importance to minority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bf2ded1-4874-4ada-87ee-0c079bea7b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 0.7709\n",
      "Fold 2: 0.7303\n",
      "Fold 3: 0.7640\n",
      "Fold 4: 0.7640\n",
      "Fold 5: 0.7584\n",
      "Mean CV Score: 0.7576\n",
      "Standard Deviation of CV Scores: 0.0142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Load and preprocess your data (as you've shown in your code)\n",
    "\n",
    "# Create a decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Combine your features and labels for training\n",
    "X = X_train\n",
    "y = Y_train\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # You can adjust the random_state as needed\n",
    "\n",
    "# Store the cross-validation scores\n",
    "cv_scores = cross_val_score(decision_tree, X_train, Y_train, cv=kf)\n",
    "\n",
    "# Print the cross-validation scores for each fold\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Fold {i}: {score:.4f}\")\n",
    "\n",
    "# Calculate the mean and standard deviation of the cross-validation scores\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "\n",
    "print(f\"Mean CV Score: {mean_cv_score:.4f}\")\n",
    "print(f\"Standard Deviation of CV Scores: {std_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd7684-9e91-4fce-aae2-50b544538e05",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px;\"> Explanation </span>\n",
    "\n",
    "We've used a technique called K-Cross-Validation. This lowers the likelihood of underfitting and overfitting. This involves taking ‘k’ distinct folds where the model is trained on the remaining k-1 folds, and then the last fold is used for validation. K is typically 5 or 10. 5 is quicker and also sufficient for smaller training sets. Cross validation can be computationally expensive but you can use GPUs to parallelise for increased efficiency. You have to balance desire for accuracy vs computational cost.\n",
    "\n",
    "- Precision is the ratio of true positives to the sum of true and false positives. When it's high, this means that when the model predicts a positive class, it’s likely to be correct. \n",
    "- Accuracy is the ratio of correct predictions to the total no. of data points. \n",
    "- Recall (sensitivity) is about how many positive predictions the model made relative to the actual no. of positive predictions. Precision can be very high if the model just classifies - everything positively.\n",
    "- The F1 score is a way of balancing precision and recall. You can increase precision and reduce recall, for example. This takes a harmonic mean of the two, creating a sort of trade off.\n",
    "\n",
    "Currently we correctly predict correctly 69% of the time, which seems pretty low. It may be due to the inbalanced class sizes (most people died) which decision trees don't handle particularly well. If you have more datapoints in a class, when you take measures like Gini impurity or variance, they tend to choose variables which favour the dominant class. Techniques like class weighting, oversampling or undersampling (duplicating datapoints in minority classes and removing datapoints in majority classes, respectively) can help with this.\n",
    "\n",
    "Decision trees do not scale particularly well. They are prone to overfitting (though not in this case). \n",
    "\n",
    "<span style=\"font-size: 20px;\"> K-nearest neighbors </span> \n",
    "\n",
    "K-nearest neighbours finds k nearest points to new data points and uses them to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd312a6-f2d6-49f1-bac7-b9eab490e52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8134328358208955\n",
      "Precision: 0.8351648351648352\n",
      "Recall: 0.6846846846846847\n",
      "F1-score: 0.7524752475247525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model using different metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "precision = precision_score(y_test, y_pred_knn)\n",
    "recall = recall_score(y_test, y_pred_knn)\n",
    "f1 = f1_score(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a93fa-cb42-4e8f-8ec9-e3ffdeb8bda3",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px;\"> Explanation </span>\n",
    "\n",
    "KNN is also very easy to implement, and actually performs better than the decision tree on this problem. It has a better trade-off between precision and recall, as indicated by the higher recall and F1-score values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ea4d0-c23b-47b1-93ef-70e79090b275",
   "metadata": {},
   "source": [
    "The next step would be to use an ensemble method like Random Forests or Gradient Boosting (XGBoost) which combine multiple decision trees to improve performance. We could also try logistic regression and support vector machines. A deep learning model would be more appropriate for a larger data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
